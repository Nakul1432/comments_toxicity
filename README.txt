This repository contains an AI model designed to analyze and classify the toxicity level of user comments.
The model can detect various forms of toxic content including hate speech, threats, obscenity, insults, and identity-based attacks.

